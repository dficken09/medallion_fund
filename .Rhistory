!c("customer_id", "training_sample"), with = FALSE]
validation_DT = crm_DT[training_sample == 0,
!c("customer_id", "training_sample"), with = FALSE]
set.seed(961)
N_obs_training = nrow(training_DT)
folds = sample(1:10, N_obs_training, replace = TRUE)
########### Linear Models with treatment interactions  ###############
### OLS
#fit_OLS = lm(outcome_spend ~ .*W, data = training_DT)
#saveRDS(fit_OLS, "fit_OLS")
fit_OLS = readRDS("fit_OLS")
summary_OLS = summary(fit_OLS)
results = data.table(input   = rownames(summary_OLS$coefficients),
est_OLS = summary_OLS$coefficients[, 1],
p_OLS   = summary_OLS$coefficients[, 4])
### LASSO
# make the model matrix for the LASSO
X = model.matrix(outcome_spend ~ 0 + .*W, data = training_DT)
y = training_DT$outcome_spend
#fit_LASSO = cv.glmnet(x=X, y=y, nfolds = 10, foldid = folds) # alpha = 1 is standard
#saveRDS(fit_LASSO, "fit_LASSO")
fit_LASSO = readRDS("fit_LASSO")
results[, est_LASSO := coef(fit_LASSO, s = "lambda.min")[,1]]
############ Non-parametric Estimator  ####################
### Causal Forest
# the *predicted* conditional average treatment effects from a causal forest are
# included in the file `Predicted-Causal-Forest-CATE.RData`.
# The causal forest was estimated using 1000 trees.
load("Predicted-Causal-Forest-CATE.RData")
predict_DT = crm_DT[training_sample == 0,
c("customer_id", "outcome_spend", "W"), with = FALSE]
### add predictions for OLS
predict_DT[, y_OLS := predict(fit_OLS, newdata = validation_DT)]
### add predictions for LASSO
new_X = model.matrix(outcome_spend ~ 0 + .*W, data = validation_DT)
predict_DT[,y_LASSO := predict(fit_LASSO, newx = new_X, s = "lambda.min")]
######## find individual heterogeneous treatment effects for the following:
### OLS
# change dataset so that W = 1
W_valid = copy(validation_DT)
W_valid[, W:= 1]
predict_W_OLS = predict(fit_OLS, newdata = W_valid)
# change dataset so that W = 0
no_W_valid = copy(validation_DT)
no_W_valid[, W:= 0]
predict_no_W_OLS = predict(fit_OLS, newdata = no_W_valid)
# find heterogeneous treatment effect usng OLS
tau_OLS = predict_W_OLS - predict_no_W_OLS
### LASSO
# create model.matrix with W = 1
X_with_W = model.matrix(outcome_spend ~ 0 + .*W, data = W_valid)
predict_W_LASSO = predict(fit_LASSO, newx = X_with_W, s = "lambda.min")
# create model.matrix with W = 0
X_no_W = model.matrix(outcome_spend ~ 0 + .*W, data = no_W_valid)
predict_no_W_LASSO = predict(fit_LASSO, newx = X_no_W, s = "lambda.min")
# find heterogeneous treatment effect usng LASSO
tau_LASSO = predict_W_LASSO - predict_no_W_LASSO
predict_DT = cbind.data.frame(predict_DT, tau_OLS, tau_LASSO)
### merge Causal Forest with predict_DT
predict_DT = merge(predict_DT, predict_DT_2017)
### tau_LASSO is just vector not named vector so have to provide column name
colnames(predict_DT)[7]<-"tau_LASSO"
saveRDS(predict_DT,"predict_DT")
mean_spend_0 = mean(predict_DT[W == 0, outcome_spend])
mean_spend_1 = mean(predict_DT[W == 1, outcome_spend])
ATE = mean_spend_1 - mean_spend_0
cat(mean_spend_0, mean_spend_1, ATE)
# Summarize and graph the distribution of the predicted heterogeneous treatment effects, tau_i, from the different estimation methods.
require(gridExtra)
hist_OLS<-ggplot(predict_DT, aes(x=tau_OLS)) +
geom_histogram(binwidth = 1, center = 0.5, color = "gray30", fill = "darkorchid3", alpha = 0.5) +
scale_x_continuous("CATE - OLS", limits = c(-40, 50)) +
scale_y_continuous("Frequency") + theme_bw()
hist_LASSO<-ggplot(predict_DT, aes(x=tau_LASSO)) +
geom_histogram(binwidth = 1, center = 0.5, color = "gray30", fill = "darkorchid3", alpha = 0.5) +
scale_x_continuous("CATE - LASSO", limits = c(-40, 50)) +
scale_y_continuous("Frequency") + theme_bw()
hist_cforest<-ggplot(predict_DT, aes(x=tau_cforest)) +
geom_histogram(binwidth = 1, center = 0.5, color = "gray30", fill = "darkorchid3", alpha = 0.5) +
scale_x_continuous("CATE - Causal Forest", limits = c(-40, 50)) +
scale_y_continuous("Frequency") + theme_bw()
grid.arrange(hist_OLS, hist_LASSO, hist_cforest, ncol=1, nrow=3)
cor_matrix = cor(predict_DT[, c("tau_OLS", "tau_LASSO", "tau_cforest"),
with = FALSE])
kable(cor_matrix)
### Use the lift table function from assignment 6 and modify it so we can calculate lifts given W = 0/1
liftTable <- function(model_name, w, y, score, N_groups = 10) {
DT = data.table(w     = w,
y     = y,
score = score)
DT[, score_group := as.integer(cut_number(score, n = N_groups))]
DT[, y_1 := ifelse(w==1, y, NA)]
DT[, y_0 := ifelse(w==1, NA, y)]
lift_DT = DT[, .(model      = model_name,
score      = mean(score),
y          = mean(y_1, na.rm=T) - mean(y_0,na.rm = T),
N          = .N,
std_error  = sqrt((sd(y_1, na.rm = T)^2)/(length(complete.cases(y_1))) +
(sd(y_0, na.rm = T)^2)/(length(complete.cases(y_0))))),
keyby = score_group]
lift_DT[, `:=`(lower  = y + qt(0.025, df = N-1)*std_error,
upper  = y + qt(0.975, df = N-1)*std_error)]
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100*y/mean(y)]
return(lift_DT)
}
lift_OLS <- liftTable("OLS Lift", predict_DT$W, predict_DT$outcome_spend, predict_DT$tau_OLS, 20)
lift_LASSO<- liftTable("LASSO Lift", predict_DT$W, predict_DT$outcome_spend, predict_DT$tau_LASSO, 20)
lift_cforest<-liftTable("Causal Forest Lift", predict_DT$W, predict_DT$outcome_spend, predict_DT$tau_cforest, 20)
lift_table = rbind.data.frame(lift_OLS, lift_LASSO, lift_cforest)
lift_table[, model := factor(model, levels = c("OLS Lift", "LASSO Lift","Causal Forest Lift"))]
kable(lift_table)
N_groups = 20
ggplot(lift_table, aes(x = score_group, y = y)) +
geom_errorbar(aes(ymin = lower, ymax = upper), color = "deepskyblue2",
size = 0.6, width = 0.1) +
geom_point(shape = 21, color = "gray30", fill = "hotpink", size = 2.5) +
scale_x_continuous("Score", limits = c(1, N_groups),
breaks = seq(0, N_groups, 5), minor_breaks = 1:N_groups) +
scale_y_continuous("Average Treatment Effects",
breaks = seq(0, 60, 10)) +
facet_wrap(~ model, ncol = 1) +
theme_bw()
margin = 0.325          # 32.5 percent
cost   = 0.99           # 99 cents
top_percent = seq(from = 0, to = 1, by = 0.01)
### grab the predictProfit function from solution in assignment 6 and modify it accordingly
predictProfitTopPercent <- function(model_name, top_percent, score, W, spend, margin, cost) {
# Observed profits for treated and untreated units
profit_0 = margin*spend
profit_1 = margin*spend - cost
# Output table
K = length(top_percent)
profits_DT = data.table(model_name  = model_name,
top_percent = top_percent,
profit      = rep(0.0, K))
scale_factor = 1000/length(W)
for (k in 1:K) {
if (top_percent[k] < 1e-12) {
threshold = max(score) + 1             # Make sure everyone is included
} else if (top_percent[k] > 1 - 1e-12) {
threshold = min(score) - 1             # Make sure nobody is included
} else {
threshold = quantile(score, probs = 1 - top_percent[k])
}
T = score >= threshold   # Indicator: Is a customer among the top percent?
N_0 = sum(1-T)           # Number of customers not among the top percent
N_1 = sum(T)             # Number of customers among the top percent
# Now calculate the mean profits for the treated and untreated units
mean_profit_0 = sum((1-T)*(1-W)*profit_0)/sum((1-T)*(1-W))
mean_profit_1 = sum(T*W*profit_1)/sum(T*W)
if (is.nan(mean_profit_0)) mean_profit_0 = 0.0
if (is.nan(mean_profit_1)) mean_profit_1 = 0.0
profits_DT[k, profit := scale_factor*(N_1*mean_profit_1 + N_0*mean_profit_0)]
}
return(profits_DT)
}
### OLS model profits
OLS_profits = predictProfitTopPercent("OLS", top_percent, predict_DT$tau_OLS, predict_DT$W, predict_DT$outcome_spend, margin, cost)
OLS_profits
OLS_opt_n_index = OLS_profits[which.max(OLS_profits$profit), top_percent]; OLS_opt_n_index
max(OLS_profits$profit)
### LASSO model profits
LASSO_profits = predictProfitTopPercent("LASSO", top_percent, predict_DT$tau_LASSO, predict_DT$W, predict_DT$outcome_spend, margin, cost)
LASSO_profits
LASSO_opt_n_index = OLS_profits[which.max(LASSO_profits$profit), top_percent]; LASSO_opt_n_index
max(LASSO_profits$profit)
### Causal Forest profits
cforest_profits = predictProfitTopPercent("Causal Forest", top_percent, predict_DT$tau_cforest, predict_DT$W, predict_DT$outcome_spend, margin, cost)
cforest_profits
cforest_opt_n_index = OLS_profits[which.max(cforest_profits$profit), top_percent]; cforest_opt_n_index
max(cforest_profits$profit)
##### combine the tables into one profit_table
profit_DT<-rbind.data.frame(OLS_profits, LASSO_profits, cforest_profits)
profit_DT[, model_name := factor(model_name, levels = c("OLS", "LASSO","Causal Forest"))]
ggplot(profit_DT, aes(x = top_percent, y = profit)) +
geom_hline(data = profit_DT[top_percent == 0, .(model_name, profit_0 = profit)],
aes(yintercept = profit_0), color = "slategray3", size = 1) +
geom_line(color = "mediumvioletred", size = 1) +
scale_x_continuous("Percent targeted", limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous("Profit", limits = c(1800, 2400),
breaks = seq(1800, 2400, 50)) +
theme_bw() +
facet_wrap(~ model_name, nrow = 3)
#load("/classes/3710501_spr2019/Data/Assignment-7/Randomized-Implementation-Sample-2018.RData")
load("Randomized-Implementation-Sample-2018.RData")
# change mailing_indicator to "W" as we did before
setnames(crm_DT, "mailing_indicator", "W")
# create new predict_DT datatable to store predictions vs. actual results
new_predict_DT = crm_DT[,c("customer_id", "outcome_spend", "W"), with = FALSE]
####### 1. Use the model predictions based **only on the 2017 data**. #######
# fit_OLS
# fit_LASSO
# causal forest given to us
####### 2. Predict heterogeneous treatment effects for the customers in the October 2018 data. #######
### OLS prediction
# need to match colnames in 2018 data to validation_DT colnames for prediction
X_2018 = subset(crm_DT, select = names(validation_DT))
X_W_2018 = copy(X_2018)
X_no_W_2018 = copy(X_2018)
X_W_2018[, W:= 1]
X_no_W_2018[, W:=0]
predict_W_2018 = predict(fit_OLS, newdata = X_W_2018)
predict_no_W_2018 = predict(fit_OLS, newdata = X_no_W_2018)
# find heterogeneous treatment effect usng OLS
tau_OLS = predict_W_2018 - predict_no_W_2018
### LASSO prediction
# create model.matrix with W = 1
X_with_W = model.matrix(outcome_spend ~ 0 + .*W, data = X_W_2018)
predict_W_LASSO = predict(fit_LASSO, newx = X_with_W, s = "lambda.min")
# create model.matrix with W = 0
X_no_W = model.matrix(outcome_spend ~ 0 + .*W, data = X_no_W_2018)
predict_no_W_LASSO = predict(fit_LASSO, newx = X_no_W, s = "lambda.min")
# find heterogeneous treatment effect usng LASSO
tau_LASSO = predict_W_LASSO - predict_no_W_LASSO
new_predict_DT<-cbind.data.frame(new_predict_DT, tau_OLS, tau_LASSO)
### Causal prediction - need to merge new_predict_DT with predict_DT_2018
new_predict_DT<-merge(new_predict_DT, predict_DT_2018)
setnames(new_predict_DT, "1", "tau_LASSO")
### sanity check on calculations
cor_matrix = cor(new_predict_DT[, c("tau_OLS", "tau_LASSO", "tau_cforest"),
with = FALSE])
kable(cor_matrix)
######## 3. Evaluate the model predictions using the 2018 data. #######
# create lift tables to examine different models' abilities to predict CATE
new_lift_OLS <- liftTable("OLS Lift", new_predict_DT$W, new_predict_DT$outcome_spend, new_predict_DT$tau_OLS, 20)
new_lift_LASSO<- liftTable("LASSO Lift", new_predict_DT$W, new_predict_DT$outcome_spend, new_predict_DT$tau_LASSO, 20)
new_lift_cforest<-liftTable("Causal Forest Lift", new_predict_DT$W, new_predict_DT$outcome_spend, new_predict_DT$tau_cforest, 20)
new_lift_table = rbind.data.frame(new_lift_OLS, new_lift_LASSO, new_lift_cforest)
new_lift_table[, model := factor(model, levels = c("OLS Lift", "LASSO Lift","Causal Forest Lift"))]
kable(new_lift_table)
# graph the lifts for the 2018 data
N_groups = 20
ggplot(new_lift_table, aes(x = score_group, y = y)) +
geom_errorbar(aes(ymin = lower, ymax = upper), color = "deepskyblue2",
size = 0.6, width = 0.1) +
geom_point(shape = 21, color = "gray30", fill = "hotpink", size = 2.5) +
scale_x_continuous("Score", limits = c(1, N_groups),
breaks = seq(0, N_groups, 5), minor_breaks = 1:N_groups) +
scale_y_continuous("Average Treatment Effects",
breaks = seq(0, 60, 10)) +
facet_wrap(~ model, ncol = 1) +
theme_bw()
### use the predictProfit function to examine profits using 2018 data
### OLS model profits
OLS_profits = predictProfitTopPercent("OLS", top_percent, new_predict_DT$tau_OLS, new_predict_DT$W, new_predict_DT$outcome_spend, margin, cost)
OLS_profits
new_OLS_opt_n_index = OLS_profits[which.max(OLS_profits$profit), top_percent]; new_OLS_opt_n_index
max(OLS_profits$profit)
### LASSO model profits
LASSO_profits = predictProfitTopPercent("LASSO", top_percent, new_predict_DT$tau_LASSO, new_predict_DT$W, new_predict_DT$outcome_spend, margin, cost)
LASSO_profits
new_LASSO_opt_n_index = OLS_profits[which.max(LASSO_profits$profit), top_percent]; new_LASSO_opt_n_index
max(LASSO_profits$profit)
### Causal Forest profits
cforest_profits = predictProfitTopPercent("Causal Forest", top_percent, new_predict_DT$tau_cforest, new_predict_DT$W, new_predict_DT$outcome_spend, margin, cost)
cforest_profits
new_cforest_opt_n_index = OLS_profits[which.max(cforest_profits$profit), top_percent]; new_cforest_opt_n_index
max(cforest_profits$profit)
##### combine the tables into one profit_table
new_profit_DT<-rbind.data.frame(OLS_profits, LASSO_profits, cforest_profits)
new_profit_DT[, model_name := factor(model_name, levels = c("OLS", "LASSO","Causal Forest"))]
ggplot(new_profit_DT, aes(x = top_percent, y = profit)) +
geom_hline(data = new_profit_DT[top_percent == 0, .(model_name, profit_0 = profit)],
aes(yintercept = profit_0), color = "slategray3", size = 1) +
geom_line(color = "mediumvioletred", size = 1) +
scale_x_continuous("Percent targeted", limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous("Profit", limits = c(1600, 2100),
breaks = seq(1600, 2100, 50)) +
theme_bw() +
facet_wrap(~ model_name, nrow = 3)
# show new vs. old best "top percent n"
new_OLS_opt_n_index; OLS_opt_n_index
OLS_profits[OLS_opt_n_index,]
OLS_profits[OLS_opt_n_index,]
OLS_profits[OLS_opt_n_index,]
OLS_profits
OLS_opt_n_index
OLS_profits[which(OLS_profits$top_percent==OLS_opt_n_index),]
#### use prior percentages determined in 2017 data to compare three models profits
#### OLS profit ####
# show old vs. new best "top percent n"
OLS_opt_n_index; new_OLS_opt_n_index
# show profits at the old, predetermined "best percentage"
OLS_profits[which(OLS_profits$top_percent==OLS_opt_n_index),]
#### LASSO profit ####
# show old vs. new best "top percent n"
LASSO_opt_n_index; new_LASS_opt_n_index
#### use prior percentages determined in 2017 data to compare three models profits
#### OLS profit ####
# show old vs. new best "top percent n"
OLS_opt_n_index; new_OLS_opt_n_index
# show profits at the old, predetermined "best percentage"
OLS_profits[which(OLS_profits$top_percent==OLS_opt_n_index),]
#### LASSO profit ####
# show old vs. new best "top percent n"
LASSO_opt_n_index; new_LASSO_opt_n_index
# show profits at the old, predetermined "best percentage"
LASSO_profits[which(LASSO_profits$top_percent==LASSO_opt_n_index),]
#### Causal Forest profit ####
# show old vs. new best "top percent n"
cforest_opt_n_index; new_cforest_opt_n_index
# show profits at the old, predetermined "best percentage"
cforest_profits[which(cforest_profits$top_percent==cforest_opt_n_index),]
### find top n = 0, top n = 100 profits
head(new_profit_DT,1)
tail(new_profit_DT,1)
2385-1886
2023-1683
#### use prior percentages determined in 2017 data to compare three models profits
#### OLS profit ####
# show old vs. new best "top percent n"
OLS_opt_n_index; new_OLS_opt_n_index
# show profits at the old, predetermined "best percentage"
OLS_profits[which(OLS_profits$top_percent==OLS_opt_n_index),]
#### LASSO profit ####
# show old vs. new best "top percent n"
LASSO_opt_n_index; new_LASSO_opt_n_index
# show profits at the old, predetermined "best percentage"
LASSO_profits[which(LASSO_profits$top_percent==LASSO_opt_n_index),]
#### Causal Forest profit ####
# show old vs. new best "top percent n"
cforest_opt_n_index; new_cforest_opt_n_index
# show profits at the old, predetermined "best percentage"
cforest_profits[which(cforest_profits$top_percent==cforest_opt_n_index),]
shiny::runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp()
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp()
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
shiny::runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
62000*1.5*10^6
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
tagList("URL link:", a("CAPM - Investopedia", href="https://www.investopedia.com/terms/c/capm.asp")),
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
runApp('Google Drive/Medallion Fund/data_grabber')
shiny::runApp('Google Drive/Medallion Fund/data_grabber')
setwd("~/Google Drive/Medallion Fund/app_files")
source('~/Google Drive/Medallion Fund/app_files/s_p_data.R', echo=TRUE)
shiny::runApp()
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
stock_db
sp_list
stock_db
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
get_stock_data("TSLA")
install.packages("XML")
install.packages("XML")
library(XML)
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
table
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
temp<-get_stock_data("AAPL")
temp$data1
str(temp$data1)
?hmtlTreeParse()
?readHTMLTable()
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
temp = get_stock_data("AAPL")
temp
temp$data1
as.character(temp$data1)
source('~/Google Drive/Medallion Fund/app_files/finviz.R', echo=TRUE)
get_stock_data("AAPL")
source('~/Google Drive/Medallion Fund/app_files/s_p_data.R', echo=TRUE)
stock_db
sp_list
shiny::runApp()
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
sector_list
sector_list[[1]]
sp_list
runApp()
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
sector_list
names(sector_list)
sector_sums = data.frame()
for (i in names(sector_list)){
Sector = i
##### Sum ####
sum_temp = sector_list[[i]]
print(Sector)
MktCap = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$`Market Cap`[!grepl("^-$",sum_temp[,"Market Cap"],)]), function(x) eval(parse(text=x))))
Income = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$Income[!grepl("^-$",sum_temp[,"Income"],)]), function(x) eval(parse(text=x))))
Sales = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$Sales[!grepl("^-$",sum_temp[,"Sales"],)]), function(x) eval(parse(text=x))))
Employees = sum(as.numeric(sum_temp$Employees[!grepl("^-$",sum_temp[,"Employees"],)]))
AvgVol = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp[,"Avg Volume"]), function(x) eval(parse(text=x))))
sector_temp = cbind.data.frame(Sector,MktCap,Income,Sales,Employees,AvgVol)
sector_sums = rbind.data.frame(sector_sums,sector_temp)
}
sector_list$Industrials
sector_list$Industrials$`Market Cap`
str(sector_list$Industrials$`Market Cap`)
str(sector_list$Industrials)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
sector_list$Industrials
temp <- sector_list$Industrials
str(temp)
temp$`Market Cap`
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
str(temp)
temp<-sector_list$Industrials
temp
str(temp)
temp[,"Market.Cap"]
sum_temp<-temp
sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$Market.Cap[!grepl("^-$",sum_temp[,"Market.Cap"],)]), function(x) eval(parse(text=x))))
sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$Income[!grepl("^-$",sum_temp[,"Income"],)]), function(x) eval(parse(text=x))))
Sales = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp$Sales[!grepl("^-$",sum_temp[,"Sales"],)]), function(x) eval(parse(text=x))))
Employees = sum(as.numeric(sum_temp$Employees[!grepl("^-$",sum_temp[,"Employees"],)]))
AvgVol = sum(sapply(gsubfn('\\D', list(B='*1e9', M='*1e6',K='1e3'), sum_temp[,"Avg Volume"]), function(x) eval(parse(text=x))))
str(sum_temp)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/sector_analyzer.R', echo=TRUE)
runApp()
runApp()
source('~/Google Drive/Medallion Fund/app_files/s_p_data.R', echo=TRUE)
source('~/Google Drive/Medallion Fund/app_files/s_p_data.R', echo=TRUE)
str(sp_list)
runApp()
runApp()
stock_db
str(stock_db)
row.names(stock_db)
str(stock_db)
stock_db<-data.frame(lapply(stock_db, as.character), stringsAsFactors = F)
saveRDS(stock_db,"stock_db")
runApp()
table_converter("AAPL","Income")
list_of_tickers=c("FB","GOOG","AMZN","AAPL")
#
column_name = "Income"
tick_idx = which(row.names(stock_db) %in% list_of_tickers)
tick_idx
list_of_tickers
row.names(stock_db)
stock_db
temp = readRDS("stock_db")
str(temp)
row.names(stock_db)
stock_db = data.frame()
for (i in symbol_list){
temp = get_stock_data(i)
stock_db=rbind.data.frame(stock_db, temp)
}
stock_db = data.frame()
for (i in symbol_list){
temp = get_stock_data(i)
stock_db=rbind.data.frame(stock_db, temp)
}
